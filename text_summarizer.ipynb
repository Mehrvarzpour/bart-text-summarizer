{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN1-ZgYGg79t",
        "outputId": "f07141d5-8101-41ec-9435-57ed3fe0f1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "\n",
            " 97 per cent of climbers use oxygen to ascend Mount Everest's summit. The mountain is 8,850 metres above sea level. The author has written three books, including The Invisible Border.\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries (run only once)\n",
        "!pip install -q transformers torch\n",
        "\n",
        "# Import dependencies\n",
        "import torch\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Input text (replace this with your own)\n",
        "text = \"\"\"\n",
        "When you picture mountain climbers scaling Mount Everest, what probably comes to mind are teams of climbers with Sherpa guides leading them to the summit, equipped with oxygen masks, supplies and tents. And in most cases you'd be right, as 97 per cent of climbers use oxygen to ascend to Everest's summit at 8,850 metres above sea level...\n",
        "...and has written three books, Run or Die, The Invisible Border and Summits of My Life.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize and prepare the input for the model\n",
        "inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "# Generate the summary\n",
        "summary_ids = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_length=100,\n",
        "    min_length=30,\n",
        "    num_beams=4,\n",
        "    length_penalty=2.0,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"\\nSummary:\\n\")\n",
        "print(summary)\n"
      ]
    }
  ]
}